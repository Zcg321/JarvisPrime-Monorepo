vocab_size: 50000
max_seq_len: 256
d_model: 256
n_heads: 8
kv_heads: 1
n_layers: 4
ffn_mult: 4.0
dropout: 0.0
rope_base: 10000
moe:
  enabled: true
  experts: 4
  top_k: 2
  capacity_factor: 1.2
  dropout: 0.0
init:
  std: 0.02
train:
  block_size: 128
  micro_bsz: 2
  grad_accum: 2
  epochs: 1
  lr: 2.0e-4
  warmup_steps: 5
  bf16: false
  grad_checkpoint: false
  compile: false
save_every_steps: 50
